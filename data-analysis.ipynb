{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b049bae9-a521-4523-9c26-864a00691bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es 43608 -10\n",
      "it 43608 -68\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for lang in ['es', 'it']:\n",
    "    df = pd.io.json.read_json(path_or_buf=f'./data/train-data_all/{lang}.train.json', orient=\"records\")\n",
    "    # patch to hashable\n",
    "    df[\"sgns\"] = df.sgns.apply(tuple)\n",
    "    df[\"char\"] = df.char.apply(tuple)\n",
    "    len_df = len(df)\n",
    "    len_df_sgns_dedup = len(df.drop_duplicates(subset=[\"gloss\", \"sgns\"]))\n",
    "    print(lang, len_df, len_df_sgns_dedup - len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a636a01a-fe57-4c72-a6e1-9384b97b74b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en 43608 -12301 0\n",
      "fr 43608 -9111 0\n",
      "ru 43608 -12375 -2\n"
     ]
    }
   ],
   "source": [
    "for lang in ['en', 'fr', 'ru']:\n",
    "    df = pd.io.json.read_json(path_or_buf=f'./data/train-data_all/{lang}.train.json', orient=\"records\")\n",
    "    # patch to hashable\n",
    "    df[\"sgns\"] = df.sgns.apply(tuple)\n",
    "    df[\"char\"] = df.char.apply(tuple)\n",
    "    df[\"electra\"] = df.electra.apply(tuple)\n",
    "    len_df = len(df)\n",
    "    len_df_sgns_dedup = len(df.drop_duplicates(subset=[\"gloss\", \"sgns\"]))\n",
    "    len_df_full_dedup = len(df.drop_duplicates(subset=[\"gloss\", \"sgns\", \"electra\"]))\n",
    "    print(lang, len_df, len_df_sgns_dedup - len_df, len_df_full_dedup - len_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6da01b-1179-4de1-9fa0-1888c8c1b75d",
   "metadata": {},
   "source": [
    "All word2vec SGNS and ELECTRA embeddings models for the 5 languages were trained on comparable datasets:\n",
    "- around 1 billion sentences in total \n",
    "- 50% of the sentences came from wikipedia, 40% came from  open subtitles, the rest were drawn from book corpora such as wikisource or gutenberg.org\n",
    "- to normalize whitespaces, all sentences were tokenized with NLTK's word_tokenize \n",
    "\n",
    "Some analysis. \n",
    "- The SGNS models were found to perform comparably to other off-the-shelf word2vec models on word analogy tasks. \n",
    "- The character embeddings achieved a 98% reconstruction accuracy on a held-out test set\n",
    "\n",
    "By \"external resources\", we mean both external datasets (such as wordnet or raw corpus data to train a LM) as well as  pretrained models, such as BERT and the like. \n",
    "You are, on the other hand, free to train language models on the CoDWoE datasets themselves.\n",
    "\n",
    "The electra vectors were computed from examples of usage: we embedded the full example of usage, and then extracted the embeddings corresponding to the word being defined. \n",
    "\n",
    "Some entries have more than one such example of usage; for a concrete example, see https://fr.wiktionary.org/wiki/plastique#Nom_commun_2 which lists three examples, with the definiendum in bold. In such cases, we computed distinct electra vectors for each example of usage, and these correspond to distinct items in the CODWOE datasets. \n",
    "These items therefore have distinct electra vectors, but the same SGNS and char vectors, as well as the same glosses. This case only occurs in the EN/FR/RU datasets.\n",
    "\n",
    "Another case of duplicate glosses is due to distinct words that are defined with the same gloss in the original dataset. In the CODWOE datasets, they correspond to items with different SGNS and char vectors, but the same gloss. These are present in all datasets, including the ES /IT datasets. \n",
    "\n",
    "Lastly, a few entries (around 0.03% of all items)  in our sources had the same word, with the same gloss, but with different POS. These did produce true duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4c487-65a9-40df-a61d-858ff0843a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
